\documentclass{beamer}
\usepackage{booktabs}
\usepackage{pdfpages}
\usepackage{mathtools}
\usepackage{enumerate}
\usepackage{multirow,tabularx}
\usepackage{booktabs}
\usepackage{pdfpages}
\usepackage{proof}
\usepackage{cancel}
\usepackage{chronology}
\usepackage{graphicx}
\usepackage{ulem}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{color}
\usepackage{animate}
\usepackage{xr}

\PassOptionsToPackage{usenames,dvipsnames,svgnames}{xcolor}  
\usepackage{tikz}
\usepackage{tkz-graph}


\usepackage{wasysym}
\usepackage{proof}
\usepackage{cancel}
\usepackage{chronology}
\usepackage{graphicx}
\usepackage{ulem}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{color}
\usepackage{xcolor}
\usepackage{soul}
%\usepackage{pstricks}
\setbeamertemplate{navigation symbols}{}

\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand{\el}{$\mathcal{EL}^{++}$}
\renewcommand{\Re}{\mathbb{R}}
\newcommand{\BigO}[1]{\ensuremath{\operatorname{O}\bigl(#1\bigr)}}
\newcommand{\myul}[2][blue]{\sethlcolor{#1}\hl{#2}\setulcolor{black}}

\newcommand<>{\cunderline}[3]{\only<#1>{#3}\only<#2>{\underline{#3}}}
\newcommand<>{\cem}[3]{\only<#1>{#3}\only<#2>{\ul{#3}}}
\newcommand<>{\cgray}[3]{\only<#1>{#3}\only<#2>{\textcolor{gray}{#3}}}
\newcommand<>{\colorize}[4]{\only<#1>{#4}\only<#2>{\textcolor{#3}{#4}}}

\setbeamertemplate{navigation symbols}{\insertslidenavigationsymbol}
%\setbeamertemplate{navigation symbols}{}
% \addtobeamertemplate{navigation symbols}{}{%
%     \usebeamerfont{footline}%
%     \usebeamercolor[fg]{footline}%
%     \hspace{1em}%
%     \insertframenumber/\inserttotalframenumber
% }

\mode<presentation>
{
\usecolortheme{crane}
%\useoutertheme{split}

\expandafter\def\expandafter\insertshorttitle\expandafter{%
  \insertshorttitle\hfill%
  \insertframenumber\,/\,\inserttotalframenumber}

\usefonttheme[onlysmall]{structurebold}
}
\renewcommand{\em}{\itshape}
\usepackage{pifont}
\definecolor{purple}{rgb}{1,0,1}
\definecolor{dred}{rgb}{0.7,0,0}
\definecolor{myred}{rgb}{1,0,0}
\definecolor{dblue}{rgb}{0,0,0.7}
\definecolor{dgreen}{rgb}{0,0.5,0}
\definecolor{myyellow}{rgb}{1,1,0}
\newcommand{\parents}[1]{parents(#1)}
\setbeamertemplate{itemize item}[ball]


% \mode<presentation>
% {
% \useinnertheme[shadow=true]{rounded}
% \useoutertheme{infolines}
% \usecolortheme{dove}
% \setbeamerfont{block title}{size={}}
% }

\title[Bio-Ontologies]{Machine learning with ontologies}

\author{Robert Hoehndorf}


\date{}

\begin{document}

\begin{frame}
  \titlepage
\end{frame}

\begin{frame}
  \frametitle{Before the tutorial}
  See \url{https://github.com/bio-ontology-research-group/ontology-tutorial}:
  \begin{itemize}
  \item install Docker (e.g.: {\tt apt-get install docker})
  \item {\tt docker pull coolmaksat/embeddings:latest}
  \item {\tt docker pull leechuck/ontology-ml:latest}
  \item {\tt docker run -i -t -p 8888:8888 leechuck/ontology-ml /bin/bash -c "jupyter notebook --notebook-dir=/home/borg/ontology-tutorial/ --ip='0.0.0.0' --port=8888 --no-browser --allow-root"}
  \end{itemize}
\end{frame}

\begin{frame}
\frametitle{Overview}
\tableofcontents
\end{frame}

\section{Ontologies and graphs}

\begin{frame}
  \frametitle{Ontologies, axioms, and bioinformatics}
  \begin{itemize}
  \item ontologies are ubiquitous
  \item rich formal characterization (axioms)
  \item how can they be used for (predictive) data analysis?
    \begin{itemize}
    \item ``fuzzy'', similarity-based search
    \item predictive analysis and machine learning
    \item background knowledge
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Learning goals}
  \begin{itemize}
  \item machine learning with ontologies as {\em features} (or
    background knowledge)
  \item unsupervised or supervised:
    \begin{itemize}
    \item here: mostly unsupervised {\em feature} learning
    \end{itemize}
  \item focus on existing tools and methods
    \begin{itemize}
    \item Jupyter Notebooks and code examples
    \end{itemize}
  \item not covered:
    \begin{itemize}
    \item learning ontologies (axioms, definitions) from data
    \item natural language processing
    \item reasoning with ontologies
    \item learning on ``knowledge graphs''
    \item machine learning theory
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Agenda}
  \begin{itemize}
  \item Introduction: ontologies, axioms, reasoning, graphs
  \item Machine learning:
    \begin{itemize}
    \item graph-based
    \item syntactic
    \item model-theoretic
    \end{itemize}
  \item (Semantic similarity)
    \begin{itemize}
    \item probably not
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Preliminaries: ontologies}
  \begin{itemize}
  \item Specific artifacts expressing the intended meaning of a
    vocabulary in terms of primitive categories and relations
    describing the nature and structure of a domain of discourse
    \begin{itemize}
    \item in order to account for the competent use of vocabulary in
      real situations (such as annotations in databases, etc.)
    \end{itemize}
  \item the intended meaning of {\em primitive} categories and
    relations is expressed through axioms (axiomatic method, Tarski)
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Preliminaries: axioms}
  \begin{itemize}
  \item {\em classes} represent kinds of things in the world
    \begin{itemize}
    \item {\em Arm}, {\em Apoptosis}, {\em Influenza}, {\em Homo
        sapiens}, {\em Drinking behavior}, {\em Membrane}
    \end{itemize}
  \item {\em instances} of classes are individuals satisfying the
    classes' intension
    \begin{itemize}
    \item my arm, the influenza I had last year, one ethanol molecule, etc.
    \end{itemize}
  \item {\em relations} between instances arise from interactions,
    configurations, etc., of individuals
    \begin{itemize}
    \item my arm is {\bf part of} me, the {\bf duration of} my
      influenza was 10 days
    \end{itemize}
  \item {\em axioms} specify the conditions that instances of a class
    must satisfy
    \begin{itemize}
    \item every instance of {\em Hand} is a {\bf part of} an instance
      of {\em Arm}
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Description Logics: overview}
  \begin{itemize}
  \item TBox: axioms pertaining to the terminology of the domain (classes)
  \item ABox: axioms stating facts (assertions) about the world
  \item RBox: axioms holding for relations
  \item Reasoning: derive implicitly represented knowledge (e.g.,
    subsumption)
  \item a ``knowledge graph'' is an ABox + RBox
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Manchester OWL Syntax}
  \begin{table}[ht]
    \centering
    \begin{tabular}{|l|l|l|}
      DL Syntax & Manchester Syntax & Example \\
      \hline
      $C \sqcap D$ & C and D & Human and Male \\
      $C \sqcup D$ & C or D & Male or Female \\
      $\neg C$ & not C & not Male \\
      $\exists R.C$ & R some C & hasChild some Human \\
      $\forall R.C$ & R only C & hasChild only Human \\
      $(\geq n R.C)$ & R min n C & hasChild min 1 Human \\
      $(\leq n R.C)$ & R max n C & hasChild max 1 Human \\
      $(= n R.C)$ & R exactly n C & hasChild exactly 1 Human \\
      $\{a\} \sqcup \{b\} \sqcup ...$ & \{a b ...\} & \{John Robert
                                                      Mary\} \\
      \hline
    \end{tabular}
  \end{table}
\end{frame}


% \begin{frame}
%   \frametitle{Description Logic ALC: syntax}
%   \begin{definition}
%     Let $N_C$ be a set of concept names and $N_R$ be a set of relation
%     names, $N_C \cap N_R = \emptyset$. $\mathcal{ALC}$ concept
%     descriptions are inductively defined as:
%     \begin{itemize}
%     \item If $A \in N_C$, then $A$ is an $\mathcal{ALC}$ concept
%       description
%     \item If $C, D$ are $\mathcal{ALC}$ concept description, and $r
%       \in N_R$, then the following are $\mathcal{ALC}$ concept descriptions:
%       \begin{itemize}
%       \item $C \sqcap D$
%       \item $C \sqcup D$
%       \item $\neg C$
%       \item $\forall r.C$
%       \item $\exists r.C$
%       \end{itemize}
%     \end{itemize}
%   \end{definition}
%   \begin{itemize}
%   \item Use $\bot$ as abbreviation of $A \sqcap \neg A$, $\top$ as
%     abbreviation of $A \sqcup \neg A$
%   \end{itemize}
% \end{frame}

% Examples of concept descriptions, dl1.pdf, p8

% \begin{frame}
%   \frametitle{Description Logic ALC: semantics}
%   \begin{definition}
%     An interpretation
%     $\mathcal{I} = (\Delta^\mathcal{I}, \cdot^\mathcal{I})$ consists
%     of a non-empty domain $\Delta^\mathcal{I}$ and an interpretation
%     function $\cdot^\mathcal{I}$:
%     \begin{itemize}
%     \item $A^\mathcal{I} \subseteq \Delta^\mathcal{I}$ for all $A \in
%       N_C$,
%     \item $r^\mathcal{I} \subseteq \Delta^\mathcal{I} \times
%       \Delta^\mathcal{I}$ for all $r \in N_R$
%     \end{itemize}
%     The interpretation function is extended to $\mathcal{ALC}$ concept
%     descriptions as follows:
%     \begin{itemize}
%     \item $(C \sqcap D)^\mathcal{I} := C^\mathcal{I} \cap D^\mathcal{I}$
%     \item $(C \sqcup D)^\mathcal{I} := C^\mathcal{I} \cup D^\mathcal{I}$
%     \item $(\neg C)^\mathcal{I} := \Delta^\mathcal{I} - C^\mathcal{I}$
%     \item $(\forall r.C)^\mathcal{I} := \{ d \in \Delta^\mathcal{I} |
%       \mbox{for all } e \in \Delta^\mathcal{I}: (d,e) \in
%       r^\mathcal{I} \mbox{ implies } e \in C^\mathcal{I}\}$
%     \item $(\exists r.C)^\mathcal{I} := \{ d \in \Delta^\mathcal{I} |
%       \mbox{there is } e \in \Delta^\mathcal{I}: (d,e) \in
%       r^\mathcal{I} \mbox{ and } e \in C^\mathcal{I}\}$
%     \end{itemize}
%   \end{definition}
% \end{frame}

% \begin{frame}
%   \frametitle{Description Logic: terminologies}
%   \begin{itemize}
%   \item A concept definition is of the form $A \equiv C$ where
%     \begin{itemize}
%     \item $A$ is a concept name
%     \item $C$ is a concept description
%     \end{itemize}
%   \item A TBox is a finite set of concept definitions such that it
%     \begin{itemize}
%     \item does not contain multiple definitions, % A equiv B, A equiv C
%     \item does not contain cyclic definitions
%       % A equiv B and C, B equiv A and C
%     \end{itemize}
%   \item A {\em defined concept} occurs on the left-hand side of a
%     definition
%   \item A {\em primitive concept} does not occur on the left-hand side
%     of a definition
%     % See: axiomatic-deductive method!
%   \item An interpretation $\mathcal{I}$ is a model of a TBox
%     $\mathcal{T}$ if it satisfies all its concept definitions:
%     $A^\mathcal{I} = C^\mathcal{I}$ for all $A \equiv C \in \mathcal{T}$
%   \end{itemize}
% \end{frame}

% \begin{frame}
%   \frametitle{Description Logic: assertions}
%   \begin{itemize}
%   \item An assertion is of the form $C(a)$ (concept assertion) or
%     $r(a,b)$ (role assertion), where $C$ is a concept description, $r$
%     is a role, $a,b$ are individual names from a set $N_I$ of such
%     names
%   \item An ABox is a finite set of assertions
%   \item An interpretation $\mathcal{I}$ is a model of an ABox
%     $\mathcal{A}$ if it satisfies all its assertions:
%     \begin{itemize}
%     \item $a^\mathcal{I} \in C^\mathcal{I}$ for all $C(a) \in
%       \mathcal{A}$
%     \item $(a^\mathcal{I},b^\mathcal{I}) \in r^\mathcal{I}$ for all
%       $r(a,b) \in \mathcal{A}$
%     \end{itemize}
%   \end{itemize}
% \end{frame}

% \begin{frame}
%   \frametitle{Description Logic: Reasoning}
%   \begin{itemize}
%   \item Subsumption: Is $C$ a subconcept of $D$?
%     \begin{itemize}
%     \item $C \sqsubseteq_\mathcal{T} D$ iff $C^\mathcal{I} \subseteq
%       D^\mathcal{I}$ for all models $\mathcal{I}$ of $\mathcal{T}$
%     \end{itemize}
%   \item Satisfiability: Is the concept $C$ non-contradictory?
%     \begin{itemize}
%     \item $C$ is satisfiable w.r.t. $\mathcal{T}$ iff $C^\mathcal{I}
%       \not= \emptyset$ for some model $\mathcal{I}$ of $\mathcal{T}$
%     \end{itemize}
%   \item Consistency: Is the ABox $\mathcal{A}$ non-contradictory?
%     \begin{itemize}
%     \item $\mathcal{A}$ is consistent w.r.t. $\mathcal{T}$ iff it has
%       a model that is also a model of $\mathcal{T}$
%     \end{itemize}
%   \item Instantiation: Is $e$ an instance of $C$?
%     \begin{itemize}
%     \item $\mathcal{A} \models_\mathcal{T} C(e)$ iff $e^\mathcal{I}
%       \in C^\mathcal{I}$ for all models $\mathcal{I}$ of $\mathcal{T}$
%       and $\mathcal{A}$.
%     \end{itemize}
%   \end{itemize}
% \end{frame}

% \begin{frame}
%   \frametitle{Offtopic: knowledge graphs}
%   My favorite definition of ``knowledge graph'':\\
%   A knowledge graph is an ABox + RBox.
%   \begin{itemize}
%   \item ontologies are (mostly) the TBox!
%   \end{itemize}
% \end{frame}

\begin{frame}
  \frametitle{Ontologies provide background knowledge}
  \centerline{\includegraphics[width=.8\textwidth]{t-cell-aggregation.png}}
\end{frame}

\begin{frame}
  \frametitle{Ontologies provide background knowledge}
  \centerline{\includegraphics[width=.8\textwidth]{t-cell-activation.png}}
\end{frame}

\begin{frame}
  \frametitle{Ontologies provide background knowledge}
  \centerline{\includegraphics[width=.95\textwidth]{moesin-1.png}}
  \centerline{\includegraphics[width=.85\textwidth]{moesin-2.png}}
  
\end{frame}

\begin{frame}
  \frametitle{Using background knowledge}
  \begin{block}{Problem statement (first attempt):}
    Given a set of biological entities and their ontology-based
    annotations. Can we discover {\em new} relations between the
    biological entities, or between entities and classes in the
    ontology?
  \end{block}
  \pause
  \begin{itemize}
  \item what relations, and when is a fact ``new''?
  \pause
  \item what features are relevant?
    \begin{itemize}
    \item depends on the relation!
    \end{itemize}
  \pause
  \item finding new facts is only one (minor?) use case
    \begin{itemize}
    \item other uses: encode background knowledge for machine learning
      models (e.g., function prediction); add new classes; expand
      definition; etc.
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Semantic similarity}
  semantic similarity measures:
  \begin{itemize}
  \item for words, terms, classes
  \item role of background knowledge:
    \begin{itemize}
    \item statistical/distributional semantics, large corpora
    \item ontologies: (graph) topology
    \end{itemize}
  \item similarity measures: hand-crafted or data-driven?
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Semantic similarity: some examples}
  \begin{itemize}
  \item Are cyclin dependent kinases {\em functionally} more similar
    to lipid kinases or to riboflavin kinases? How about {\em
      phenotypically}?
  \item Which protein in the {\em mouse} is functionally most similar
    to the zebrafish {\em gustducin} protein?
  \item Which mouse knockout resembles {\em Bardet-Biedl Syndrome 8}?
  \item Are there mouse knockouts that resemble the side effects of
    diclofenac?
  \item Which genetic disease produces similar symptoms to ebola?
  \item Does functional similarity correlate with phenotypic
    similarity?
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Semantic similarity or machine learning}
  \begin{itemize}
  \item semantic similarity measures are mostly hand-crafted
    \begin{itemize}
    \item capture certain intuition about what constitutes
      ``similarity''
    \item different measures for different kinds of similarity
    \item usually interpretable (and explainable)
    \end{itemize}
    \pause
  \item machine learning methods are mostly data-driven
    \begin{itemize}
    \item the architecture of the model is still hand-crafted
    \item usually hard to interpret
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Ontologies and graphs}
  \begin{itemize}
  \item semantic similarity measures and machine learning models on
    ontologies can be graph-based, feature-based, or model-based
    \pause
  \item we may need to generate graphs from ontologies
    \begin{itemize}
    \item {\em is-a} relations are easy (this is just {\tt owl:subClassOf})
    \item how about {\em part-of}, {\em regulates}, {\em precedes},
      etc.?
    \item disjointness, universal vs. existential quantification,
      cardinality restrictions, intersection, union, negation?
    \end{itemize}
    \pause
  \item relational patterns are implicit in OWL axioms
    \begin{itemize}
    \item in first order logic
    \item needs to translate them into OWL
    \item defined in OBO Relation Ontology
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Relations as patterns}
  \centerline{\includegraphics[height=.8\textheight]{plant-ontology-sample.png}}
\end{frame}

\begin{frame}
  \frametitle{Relations as patterns}
  \begin{itemize}
  \item OBO Relation Ontology (RO):
    \begin{itemize}
    \item \url{https://github.com/oborel/obo-relations}
    \end{itemize}
  \item Basic Formal Ontology (BFO):
    \begin{itemize}
    \item provides top-level classes
      \begin{itemize}
      \item Continuant, Process, Function, Material object, etc.
      \end{itemize}
    \item used for some OBO Foundry ontologies
    \end{itemize}
  \item RO and BFO provide a top-level system of classes and relations
    shared across many biomedical ontologies
  \item this system may define patterns used to generate graphs
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Relations as patterns}
  \begin{itemize}
  \item {\tt X SubClassOf: Y}: $X \xrightarrow{\text{is-a}} Y$
  \item {\tt X SubClassOf: part-of some Y}: $X \xrightarrow{\text{part-of}} Y$
  \item {\tt X SubClassOf: regulates some Y}: $X \xrightarrow{\text{regulates}} Y$
  \item {\tt X DisjointWith: Y}: $X \xleftrightarrow{\text{disjoint}} Y$
  \item {\tt X EquivalentTo: Y}: $X \xleftrightarrow{\equiv} Y$, $\{X,Y\}$
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Asserted and inferred}
  \begin{itemize}
  \item relation patterns can be asserted or inferred
  \item {\tt X SubClassOf: part-of some Y}
  \item {\tt Y SubClassOf: part-of some Z}
  \item {\tt part-of o part-of SubPropertyOf: part-of}
  \item $\vdash$ {\tt X SubClassOf: part-of some Z}
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Methods and tools}
  OBO Format represents ontologies as graphs:
  \begin{itemize}
  \item Protege/OWLAPI: OBO export
  \item OBO toolsets (e.g., ROBOT)
  \item
    \url{https://github.com/bio-ontology-research-group/Onto2Graph}
    \pause
  \item a conversion of an ontologies into a graph will almost always
    lead to a loss of information
    \pause
  \item edges should be ``meaningful'': not merely syntax
    \begin{itemize}
    \item the RDF serialization of OWL is a graph and contains all
      information but is a bad idea for semantic similarity or machine
      learning (more later)
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{An example: protein--protein interactions and GO functions}
  \centerline{\includegraphics[width=.49\textwidth]{YeastPPINetwork.png}
    \includegraphics[width=.49\textwidth]{go-figure1.jpg}}
\end{frame}

\section{Machine learning and ontologies}

\begin{frame}
  \frametitle{Machine learning with ontologies: approaches}
  \begin{itemize}
  \item graph-based
  \item syntactic
  \item model-theoretic
  \end{itemize}
\end{frame}

\subsection{Graph-based methods}

\begin{frame}
  \frametitle{How to measure similarity?}
  \centerline{\includegraphics[height=.8\textheight]{instances.png}}
  {\tiny From Harispe et al., Semantic Similarity From Natural
    Language And Ontology Analysis, 2015.}
\end{frame}

\begin{frame}
  \frametitle{How to measure similarity?}
  \begin{itemize}
  \item Shortest Path
    \begin{itemize}
    \item applicable to arbitrary ``knowledge graphs''
    \item does not capture similarity well over all edge types, e.g.,
      {\em disjointWith}, {\em differentFrom}, {\em opposite-of}, etc.
    \end{itemize}
  \item Random Walk
    \begin{itemize}
    \item with or without restart
    \item iterated
    \item does not consider edge labels $\Rightarrow$ captures only
      adjacency of nodes
    \item scores whole graph with {\em probability} of being in a
      state
    \item can take multiple seed nodes
      \begin{itemize}
      \item can be used to find disease genes
      \end{itemize}
    \end{itemize}
  \end{itemize}
\end{frame}


\begin{frame}
  \frametitle{Graph-based learning}
  \begin{itemize}
  \item feature learning on graphs
    \pause
  \item e.g., iterated, edge-labeled random walk
    \begin{itemize}
      % \item over instances and classes
    \item walks form {\em sentences}
    \item sentences form a {\em corpus}
    \item feature learning on corpus through Word2Vec (or factorization
      of co-occurrence matrix)
    \item RDF2Vec:
      \url{http://data.dws.informatik.uni-mannheim.de/rdf2vec/}
    \item with support for reasoning over ontologies:
      \url{https://github.com/bio-ontology-research-group/walking-rdf-and-owl}
    \end{itemize}
    \pause
  \item Translational knowledge graph embeddings: TransE, TransR, TransE, HolE, etc.
    \begin{itemize}
    \item analogy- or translation-based
    \item \url{https://github.com/SmartDataAnalytics/PyKEEN}
    \end{itemize}
    \pause
  \item Graph Convolution Neural Networks (not discussed here)
  \end{itemize}
\end{frame}

% \begin{frame}
%   \frametitle{Graph-based learning}
%   \begin{itemize}
%   \item graph-representation of the ontology
%     \begin{itemize}
%     \item taxonomy
%     \item axioms
%     \item instances (using an {\tt instance-of} edge)
%     \end{itemize}
%   \item learning with graphs:
%     \begin{itemize}
%     \item random walks (and Word2Vec)
%     \item translation embeddings
%     \end{itemize}
%   \end{itemize}
% \end{frame}

\begin{frame}
  \frametitle{Graph embeddings}
  \begin{definition}
    Let $KG = (V, E, L; \vdash)$ be an ontology graph with a set of
    vertices $V$, a set of edges $E \subseteq V \times V$, a label
    function $L: V \cup E \mapsto Lab$ that assigns labels from a set
    of labels $Lab$ to vertices and edges, and an inference relation
    $\vdash$. An ontology graph embedding is a function
    $f_\eta : L(V) \cup L(E) \mapsto \mathbf{R}^n$.
  \end{definition}
  \pause
  \begin{itemize}
  \item key idea: preserve {\em some} structure of the graph in
    $\Re^n$ (under operations in $\Re^n$)
  \item $\Re^n$ enables {\em new} operations (such as many similarity
    measures)
  \item useful as {\em feature} vectors
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Random walks}
  \begin{columns}
    \begin{column}{.6\textwidth}
      \resizebox{1\textwidth}{!}{%
        \begin{tikzpicture}
%          \SetUpEdge[lw = 1pt, color = black]
          \GraphInit[vstyle=Shade]
          \tikzset{
            LabelStyle/.style = { rectangle, rounded corners, draw,
              minimum width = 2em, fill = yellow!50,
              text = black },
            VertexStyle/.append style = { inner sep=5pt,
              font = \Large\bfseries},
            EdgeStyle/.append style = {->} }
          
          \SetGraphUnit{5}
          % \tikzset{VertexStyle/.append style={fill}}
          % \tikzset{EdgeStyle/.style={->}}
          \node[draw, color=cyan] (FOXP2) at (0,0) {FOXP2};
          \node[draw] (MET) at (3,0) {MET};
          \node[draw] (ST7) at (1.5,3) {ST7};
          \node[draw] (MAPK3) at (3,-3) {MAPK3};
          \node[draw] (GO0071625) at (-2,2.5) {GO:0071625};
          \node[draw] (GO0044708) at (-1,4.5) {GO:0044708};
          \node[draw] (TBR1) at (-3,1.5) {TBR1};
          \node[draw] (NKX2-1) at (-3,-1.5) {NKX2-1};
          \begin{scope}[/tikz/handle active characters in nodes=false]
          \Edge[label=activates](MET)(MAPK3)
          \Edge[label=hasFunction](FOXP2)(GO0071625)
          \Edge[label=hasFunction](ST7)(GO0044708)
          \Edge[label=$\sqsubseteq$](GO0071625)(GO0044708)

          \tikzset{EdgeStyle/.append style={<->}}
          \Edge[label=binds](FOXP2)(MET)
          \Edge[label=binds](FOXP2)(MAPK3)
          \Edge[label=coex](FOXP2)(TBR1)
          \Edge[label=coex](FOXP2)(NKX2-1)
          \Edge[label=coex](FOXP2)(ST7)
          \Edge[label=coex](MET)(ST7)
          \Edge[label=coex](NKX2-1)(TBR1)
          \end{scope}
          % \tikzset{EdgeStyle/.style={->}}
          % \Edge[label=hf](FOXP2)(GO0044708)
          % \draw[label=binds] (FOXP2) to (MET);
          % \Edge[label=binds](FOXP2)(MET)
          % \Edge[label=activates](MET)(MAPK3)
          % \Edge[label=coexpressed-with](FOXP2)(FOXP4)
          
        \end{tikzpicture}
      }
    \end{column}
    \begin{column}{.4\textwidth}
      \begin{itemize}
      \item FOXP2 is characterized by {\em adjacent} and close nodes
        and edges
      \item different edges may ``transmit'' information differently
      \end{itemize}
    \end{column}
  \end{columns}
      
\end{frame}

\begin{frame}
  \frametitle{Random walks}
%  \frametitle{Neuro-symbolic feature learning}
  \begin{columns}
    \begin{column}{.6\textwidth}
      \resizebox{1\textwidth}{!}{%
        \begin{tikzpicture}
%          \SetUpEdge[lw = 1pt, color = black]
          \GraphInit[vstyle=Shade]
          \tikzset{
            LabelStyle/.style = { rectangle, rounded corners, draw,
              minimum width = 2em, fill = yellow!50,
              text = black },
            VertexStyle/.append style = { inner sep=5pt,
              font = \Large\bfseries},
            EdgeStyle/.append style = {->} }
          
          \SetGraphUnit{5}
          % \tikzset{VertexStyle/.append style={fill}}
          % \tikzset{EdgeStyle/.style={->}}
          \node[draw, color=cyan] (FOXP2) at (0,0) {FOXP2};
          \node[draw] (MET) at (3,0) {MET};
          \node[draw] (ST7) at (1.5,3) {ST7};
          \node[draw] (MAPK3) at (3,-3) {MAPK3};
          \node[draw] (GO0071625) at (-2,2.5) {GO:0071625};
          \node[draw] (GO0044708) at (-1,4.5) {GO:0044708};
          \node[draw] (TBR1) at (-3,1.5) {TBR1};
          \node[draw] (NKX2-1) at (-3,-1.5) {NKX2-1};
          \begin{scope}[/tikz/handle active characters in nodes=false]
          \Edge[label=activates](MET)(MAPK3)
          \Edge[label=hasFunction](FOXP2)(GO0071625)
          \Edge[label=hasFunction](ST7)(GO0044708)
          \Edge[label=$\sqsubseteq$](GO0071625)(GO0044708)

          \tikzset{EdgeStyle/.append style={<->}}
          \Edge[label=binds](FOXP2)(MET)
          \Edge[label=binds](FOXP2)(MAPK3)
          \Edge[label=coex](FOXP2)(TBR1)
          \Edge[label=coex](FOXP2)(NKX2-1)
          \Edge[label=coex](FOXP2)(ST7)
          \Edge[label=coex](MET)(ST7)
          \Edge[label=coex](NKX2-1)(TBR1)
          \end{scope}
          % \tikzset{EdgeStyle/.style={->}}
          % \Edge[label=hf](FOXP2)(GO0044708)
          % \draw[label=binds] (FOXP2) to (MET);
          % \Edge[label=binds](FOXP2)(MET)
          % \Edge[label=activates](MET)(MAPK3)
          % \Edge[label=coexpressed-with](FOXP2)(FOXP4)
          
        \end{tikzpicture}
      }
    \end{column}
    \begin{column}{.4\textwidth}
      \begin{itemize}
      \item precompute the deductive closure:
      \item for all $\phi$: if $\mathcal{KG} \models \phi$, add $\phi$
        to $\mathcal{KG}$
      \end{itemize}
    \end{column}
  \end{columns}
      
\end{frame}

\begin{frame}
  \frametitle{Random walks}
%  \frametitle{Neuro-symbolic feature learning}
  \begin{columns}
    \begin{column}{.6\textwidth}
      \resizebox{1\textwidth}{!}{%
        \begin{tikzpicture}
%          \SetUpEdge[lw = 1pt, color = black]
          \GraphInit[vstyle=Shade]
          \tikzset{
            LabelStyle/.style = { rectangle, rounded corners, draw,
              minimum width = 2em, fill = yellow!50,
              text = black },
            VertexStyle/.append style = { inner sep=5pt,
              font = \Large\bfseries},
            EdgeStyle/.append style = {->} }
          
          \SetGraphUnit{5}
          % \tikzset{VertexStyle/.append style={fill}}
          % \tikzset{EdgeStyle/.style={->}}
          \node[draw, color=cyan] (FOXP2) at (0,0) {FOXP2};
          \node[draw] (MET) at (3,0) {MET};
          \node[draw] (ST7) at (1.5,3) {ST7};
          \node[draw] (MAPK3) at (3,-3) {MAPK3};
          \node[draw] (GO0071625) at (-2,2.5) {GO:0071625};
          \node[draw] (GO0044708) at (-1,4.5) {GO:0044708};
          \node[draw] (TBR1) at (-3,1.5) {TBR1};
          \node[draw] (NKX2-1) at (-3,-1.5) {NKX2-1};
          \begin{scope}[/tikz/handle active characters in nodes=false]
          \Edge[label=activates](MET)(MAPK3)
          \Edge[label=hasFunction](FOXP2)(GO0071625)
          \Edge[label=hasFunction](ST7)(GO0044708)
          \Edge[label=$\sqsubseteq$](GO0071625)(GO0044708)

          \tikzset{EdgeStyle/.append style={<->}}
          \Edge[label=binds](FOXP2)(MET)
          \Edge[label=binds](FOXP2)(MAPK3)
          \Edge[label=coex](FOXP2)(TBR1)
          \Edge[label=coex](FOXP2)(NKX2-1)
          \Edge[label=coex](FOXP2)(ST7)
          \Edge[label=coex](MET)(ST7)
          \Edge[label=coex](NKX2-1)(TBR1)

          \tikzset{EdgeStyle/.style={->}}
          \Edge[label=hf, color=red, style=dashed](FOXP2)(GO0044708)
          \end{scope}
          % \tikzset{EdgeStyle/.style={->}}
          % \Edge[label=hf](FOXP2)(GO0044708)
          % \draw[label=binds] (FOXP2) to (MET);
          % \Edge[label=binds](FOXP2)(MET)
          % \Edge[label=activates](MET)(MAPK3)
          % \Edge[label=coexpressed-with](FOXP2)(FOXP4)
          
        \end{tikzpicture}
      }
    \end{column}
    \begin{column}{.4\textwidth}
      \begin{itemize}
      \item precompute the deductive closure:
      \item for all $\phi$: if $\mathcal{KG} \models \phi$, add $\phi$
        to $\mathcal{KG}$
      \end{itemize}
    \end{column}
  \end{columns}
      
\end{frame}


\begin{frame}
  \frametitle{Random walks}
%  \frametitle{Neuro-symbolic feature learning}
  \begin{columns}
    \begin{column}{.6\textwidth}
      \resizebox{1\textwidth}{!}{%
        \begin{tikzpicture}
%          \SetUpEdge[lw = 1pt, color = black]
          \GraphInit[vstyle=Shade]
          \tikzset{
            LabelStyle/.style = { rectangle, rounded corners, draw,
              minimum width = 2em, fill = yellow!50,
              text = black },
            VertexStyle/.append style = { inner sep=5pt,
              font = \Large\bfseries},
            EdgeStyle/.append style = {->} }
          
          \SetGraphUnit{5}
          % \tikzset{VertexStyle/.append style={fill}}
          % \tikzset{EdgeStyle/.style={->}}
          \node[draw, color=cyan] (FOXP2) at (0,0) {FOXP2};
          \node[draw] (MET) at (3,0) {MET};
          \node[draw] (ST7) at (1.5,3) {ST7};
          \node[draw] (MAPK3) at (3,-3) {MAPK3};
          \node[draw] (GO0071625) at (-2,2.5) {GO:0071625};
          \node[draw] (GO0044708) at (-1,4.5) {GO:0044708};
          \node[draw] (TBR1) at (-3,1.5) {TBR1};
          \node[draw] (NKX2-1) at (-3,-1.5) {NKX2-1};
          \begin{scope}[/tikz/handle active characters in nodes=false]
          \Edge[label=activates](MET)(MAPK3)
          \Edge[label=hasFunction](FOXP2)(GO0071625)
          \Edge[label=hasFunction](ST7)(GO0044708)
          \Edge[label=$\sqsubseteq$](GO0071625)(GO0044708)

          \tikzset{EdgeStyle/.append style={<->}}
          \Edge[label=binds](FOXP2)(MET)
          \Edge[label=binds](FOXP2)(MAPK3)
          \Edge[label=coex](FOXP2)(TBR1)
          \Edge[label=coex](FOXP2)(NKX2-1)
          \Edge[label=coex](FOXP2)(ST7)
          \Edge[label=coex](MET)(ST7)
          \Edge[label=coex](NKX2-1)(TBR1)

          \tikzset{EdgeStyle/.style={->}}
          \Edge[label=hf, color=red, style=dashed](FOXP2)(GO0044708)
          \end{scope}
          % \draw[label=binds] (FOXP2) to (MET);
          % \Edge[label=binds](FOXP2)(MET)
          % \Edge[label=activates](MET)(MAPK3)
          % \Edge[label=coexpressed-with](FOXP2)(FOXP4)
          
        \end{tikzpicture}
      }
    \end{column}
    \begin{column}{.4\textwidth}
      \begin{itemize}
      \item Exploring the graph:
        \pause
      \item :FOXP2 :binds :MET :coex :ST7 :hasFunction GO:0044708
        \pause
      \item :FOXP2 :hasFunction GO:0071625 subClassOf GO:0044708
        \pause
      \item :FOXP2 :coex :TBR1 :coex :NKX2-1 :coex :TBR1 :coex ...
      \end{itemize}
    \end{column}
  \end{columns}
\end{frame}

\begin{frame}
  \frametitle{Word2Vec}
  Maximize:
  \begin{equation}
    \frac{1}{N} \sum_{n=1}^{N} \sum_{-c\leq j \leq c, j\not=
      0} \log p(w_{n+j}|w_n)
  \end{equation}
  with
  \begin{equation}
    p(w_o | w_i) = \frac{\exp({v'_{w_o}}^T v_{w_i})}{\sum_{w=1}^{W}
      \exp({v'_{w}}^T v_{w_i})}
  \end{equation}
  (at least conceptually; different strategies are used to approximate Eqn. 2)
\end{frame}

\begin{frame}
  \frametitle{Word2Vec}
  \centerline{\includegraphics[width=\textwidth]{word2vec-example.png}}
\end{frame}

\begin{frame}
  \frametitle{Word2Vec and Random Walks}
  \begin{itemize}
  \item random walks ``flatten'' a graph
    \begin{itemize}
    \item walks capture node neighborhood
    \item and generate a ``corpus''
    \end{itemize}
  \item random walks capture graph ``structure''
    \begin{itemize}
    \item hub-nodes, communities, etc.
    \item determine ``importance'' of nodes
    \end{itemize}
  \item embeddings capture co-occurrence
    \begin{itemize}
    \item similar graph neighborhood $\Rightarrow$ similar
      co-occurrence $\Rightarrow$ similar vector
    \end{itemize}
  \item embeddings generate ``feature'' vectors
    \begin{itemize}
    \item functions from symbols (words, labels) into $\Re^n$
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{What to do with embeddings?}
  \begin{itemize}
  \item useful for edge prediction, similarity, clustering, as feature
    vectors
    \begin{itemize}
    \item supervised: edge prediction (e.g., SVM, ANN)
      \begin{itemize}
      \item e.g.: find a function $f:\Re^n \times \Re^n \mapsto [0,1]$
        s.t. $\sqrt \frac{\sum_{t=1}^T (\hat{y_t} - y_t)^2}{T}$ (RMSE)
        is minimized for a set of true labels $y_k$
      \end{itemize}
    \item unsupervised: clustering, similarity, visualization
      \begin{itemize}
      \item cosine similarity (for L2-normalized features)
      \item Word2Vec embeddings capture similarity between co-occurrence vectors
      \end{itemize}
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Random walks}
%  \frametitle{Neuro-symbolic feature learning}
  \centerline{\includegraphics[width=\textwidth]{rdf-walking-datasets.png}}
\end{frame}

\begin{frame}
  \frametitle{Visualizing feature vectors: dimensionality reduction}
  \begin{itemize}
  \item project $n$-dimensional vectors in 2D (or 3D) space
  \item and color with some known labels
    \begin{itemize}
    \item high-level/general classes in an ontology work great
    \end{itemize}
  \item PCA or t-SNE
  \item \url{https://lvdmaaten.github.io/tsne/}
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Visualizing feature vectors}
%  \frametitle{Neuro-symbolic feature learning}
  \centerline{\includegraphics[width=\textwidth]{graph-tsne.png}}
\end{frame}

\begin{frame}
  \frametitle{Features: supervised learning}
  \begin{itemize}
  \item feature vectors represent graph neighborhood of nodes
    \begin{itemize}
    \item adjacent nodes and edges
    \item ontology classes (asserted \& inferred)
    \end{itemize}
  \item useful in supervised prediction tasks
  \item relation prediction:
    \begin{itemize}
    \item input: two features vectors (from embedding function)
    \item output: $0$ or $1$ (relation or not)
    \item training data: positive and negative cases
      \begin{itemize}
      \item $R(x,y)$ and $\neg R(x,y)$
      \end{itemize}
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Features: supervised learning}
  \resizebox{\textwidth}{!}{
  \begin{tabular}{@{}lllcccc@{}}\toprule 
      \multirow{2}{*}{Object property} 
      & Source type & Target type &\multicolumn{2}{c}{Without reasoning}&\multicolumn{2}{c}{With reasoning}\\
      &&& F-measure & AUC & F-measure & AUC \\
      \midrule
      has target & Drug & Gene/Protein & 0.94 & 0.97 & 0.94 & 0.98 \\
      has disease annotation & Gene/Protein & Disease & 0.89 & 0.95 & 0.89 & 0.95 \\
      has side-effect$^*$ & Drug & Phenotype & 0.86 & 0.93 & 0.87 & 0.94 \\
      has interaction & Gene/Protein & Gene/Protein & 0.82 & 0.88 & 0.82 & 0.88\\
      has function$^*$ & Gene/Protein & Function & 0.85 & 0.95 & 0.83 & 0.91 \\
      has gene phenotype$^*$  & Gene/Protein & Phenotype & 0.84 & 0.91 & 0.82 & 0.90  \\
      has indication & Drug & Disease & 0.72 & 0.79 & 0.76 & 0.83 \\
      has disease phenotype$^*$  & Disease & Phenotype & 0.72 & 0.78 & 0.70 & 0.77 \\
    \end{tabular}}
\end{frame}

\begin{frame}
  \frametitle{Ontologies, graphs, and text}
    \begin{quote}
      The \only<1,2>{\underline{forkhead-box P2 (FOXP2)}}\only<3>{\underline{:FOXP2}} gene polymorphism has been
      reported to be involved in the susceptibility to schizophrenia;
      however, few studies have investigated the association between
      \only<1,2>{\underline{FOXP2}}\only<3>{\underline{:FOXP2}} gene polymorphism and clinical symptoms in schizophrenia.
    \end{quote}
  \pause
  \begin{itemize}
  \item \underline{:FOXP2} :binds :MET :coex :ST7 :hasFunction GO:0044708
  \item \underline{:FOXP2} :hasFunction GO:0071625 subClassOf GO:0044708
  \item \underline{:FOXP2} :coex :TBR1 :coex :NKX2-1 :coex :TBR1 :coex ...
  \end{itemize}
\end{frame}

% \begin{frame}
%   \frametitle{Multi-modal feature learning}
%   \centerline{\includegraphics[width=\textwidth]{multimodal_workflow.pdf}}
% \end{frame}


% \begin{frame}
%   \frametitle{Multi-modal feature learning: drug targets and indications}
%   \centerline{
%     \includegraphics[width=.45\textwidth]{DTI_ANN_all.pdf}
%     \includegraphics[width=.45\textwidth]{Ind_ANN_all.pdf}
%   }
%   \vspace{.5cm}
%   {\tiny Alshahrani \& H. Drug repurposing through
%     multi-modal learning on knowledge graphs. BioRxiv, 2018.}
% \end{frame}

\begin{frame}
  \frametitle{Tools and resources}
  \begin{itemize}
  \item RDF2Vec: random walks on RDF + Word2Vec
  \item RDF2Vec: Weisfeiler-Lehmann kernel on RDF
  \item \url{https://datalab.rwth-aachen.de/embedding/RDF2Vec/}
    \pause
  \item Walking RDF+OWL: random walks on RDF + Elk + Word2Vec
    \begin{itemize}
    \item inference
    \end{itemize}
  \item \url{https://github.com/bio-ontology-research-group/walking-rdf-and-owl}
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Some limitations}
  \begin{itemize}
  \item ``word''-based (Word2Vec):
    \begin{itemize}
    \item semantics is reduced to co-occurrence (in ABox/TBox
      statements)
    \item ``disjointWith'' vs. ``part-of'' vs. ``subClassOf''
    \end{itemize}
  % \item graph-based:
  %   \begin{itemize}
  %   \item ontologies are not graphs!
  %   \item converting ontologies to graphs loses information
  %   \item no axioms, no definitions
  %   \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Jupyter excercise}
  \begin{itemize}
  \item Open the Jupyter notebook {\tt graph.ipynb}
  \item Follow the examples in the first part of the notebook (random
    walks)
  \item If you don't have a powerful CPU in your laptop (with multiple
    cores), you may want to lower the number of iterations ({\tt
      n\_iter}) during TSNE
  \item some of the code will take a while to run
    \begin{itemize}
    \item if things are too slow, you can keep it running while we
      continue or complete this after the tutorial
    \end{itemize}
  \end{itemize}
\end{frame}


\subsection{Translating embeddings}
\begin{frame}
  \frametitle{Translating embeddings}
  \begin{definition}
    Let $KG = (V, E, L; \vdash)$ be a knowledge graph with a set of
    vertices $V$, a set of edges $E \subseteq V \times V$, a label
    function $L: V \cup E \mapsto Lab$ that assigns labels from a set
    of labels $Lab$ to vertices and edges, and an inference relation
    $\vdash$. A knowledge graph embedding is a function
    $f_\eta : L(V) \cup L(E) \mapsto \mathbf{R}^n$.
  \end{definition}
  \pause
  Graph as edgelist: set of $(s,p,o)$ statements\\
  \pause
  Idea: $\mu (s) + \mu (p) \approx \mu (o)$\\
  \pause
  Minimize: $\sum_t \norm{ \mu (s) + \mu (p) - \mu (o) }$ (chose your
  norm, usually L2)
\end{frame}

\begin{frame}
  \frametitle{Translating embeddings}
  \centerline{\includegraphics[width=.7\textwidth]{transe-figure.png}}
\end{frame}

\begin{frame}
  \frametitle{Translating embeddings}
  \begin{columns}
    \begin{column}{.6\textwidth}
      \resizebox{1\textwidth}{!}{%
        \begin{tikzpicture}
%          \SetUpEdge[lw = 1pt, color = black]
          \GraphInit[vstyle=Shade]
          \tikzset{
            LabelStyle/.style = { rectangle, rounded corners, draw,
              minimum width = 2em, fill = yellow!50,
              text = black },
            VertexStyle/.append style = { inner sep=5pt,
              font = \Large\bfseries},
            EdgeStyle/.append style = {->} }
          
          \SetGraphUnit{5}
          % \tikzset{VertexStyle/.append style={fill}}
          % \tikzset{EdgeStyle/.style={->}}
          \node[draw, color=cyan] (FOXP2) at (0,0) {FOXP2};
          \node[draw] (MET) at (3,0) {MET};
          \node[draw] (ST7) at (1.5,3) {ST7};
          \node[draw] (MAPK3) at (3,-3) {MAPK3};
          \node[draw] (GO0071625) at (-2,2.5) {GO:0071625};
          \node[draw] (GO0044708) at (-1,4.5) {GO:0044708};
          \node[draw] (TBR1) at (-3,1.5) {TBR1};
          \node[draw] (NKX2-1) at (-3,-1.5) {NKX2-1};
          \begin{scope}[/tikz/handle active characters in nodes=false]
          \Edge[label=activates](MET)(MAPK3)
          \Edge[label=hasFunction](FOXP2)(GO0071625)
          \Edge[label=hasFunction](ST7)(GO0044708)
          \Edge[label=$\sqsubseteq$](GO0071625)(GO0044708)

          \tikzset{EdgeStyle/.append style={<->}}
          \Edge[label=binds](FOXP2)(MET)
          \Edge[label=binds](FOXP2)(MAPK3)
          \Edge[label=coex](FOXP2)(TBR1)
          \Edge[label=coex](FOXP2)(NKX2-1)
          \Edge[label=coex](FOXP2)(ST7)
          \Edge[label=coex](MET)(ST7)
          \Edge[label=coex](NKX2-1)(TBR1)
          \end{scope}
          % \tikzset{EdgeStyle/.style={->}}
          % \Edge[label=hf](FOXP2)(GO0044708)
          % \draw[label=binds] (FOXP2) to (MET);
          % \Edge[label=binds](FOXP2)(MET)
          % \Edge[label=activates](MET)(MAPK3)
          % \Edge[label=coexpressed-with](FOXP2)(FOXP4)
          
        \end{tikzpicture}
      }
    \end{column}
    \begin{column}{.4\textwidth}
      \begin{itemize}
        \pause
      \item FOXP2 + binds = MET
        \pause
      \item MAP + activates = MAPK3
        \pause
      \item MET + binds = FOXP2
        \pause
      \item ST7 + hasFunction = {\tt GO:0044708}
        \pause
      \item ...
      \end{itemize}
    \end{column}
  \end{columns}
\end{frame}

\begin{frame}
  \frametitle{Translating embeddings}
  \begin{columns}
    \begin{column}{.6\textwidth}
      \resizebox{1\textwidth}{!}{%
        \begin{tikzpicture}
%          \SetUpEdge[lw = 1pt, color = black]
          \GraphInit[vstyle=Shade]
          \tikzset{
            LabelStyle/.style = { rectangle, rounded corners, draw,
              minimum width = 2em, fill = yellow!50,
              text = black },
            VertexStyle/.append style = { inner sep=5pt,
              font = \Large\bfseries},
            EdgeStyle/.append style = {->} }
          
          \SetGraphUnit{5}
          % \tikzset{VertexStyle/.append style={fill}}
          % \tikzset{EdgeStyle/.style={->}}
          \node[draw, color=cyan] (FOXP2) at (0,0) {FOXP2};
          \node[draw] (MET) at (3,0) {MET};
          \node[draw] (ST7) at (1.5,3) {ST7};
          \node[draw] (MAPK3) at (3,-3) {MAPK3};
          \node[draw] (GO0071625) at (-2,2.5) {GO:0071625};
          \node[draw] (GO0044708) at (-1,4.5) {GO:0044708};
          \node[draw] (TBR1) at (-3,1.5) {TBR1};
          \node[draw] (NKX2-1) at (-3,-1.5) {NKX2-1};
          \begin{scope}[/tikz/handle active characters in nodes=false]
          \Edge[label=activates](MET)(MAPK3)
          \Edge[label=hasFunction](FOXP2)(GO0071625)
          \Edge[label=hasFunction](ST7)(GO0044708)
          \Edge[label=$\sqsubseteq$](GO0071625)(GO0044708)

          \tikzset{EdgeStyle/.append style={<->}}
          \Edge[label=binds](FOXP2)(MET)
          \Edge[label=binds](FOXP2)(MAPK3)
          \Edge[label=coex](FOXP2)(TBR1)
          \Edge[label=coex](FOXP2)(NKX2-1)
          \Edge[label=coex](FOXP2)(ST7)
          \Edge[label=coex](MET)(ST7)
          \Edge[label=coex](NKX2-1)(TBR1)
          \end{scope}
          % \tikzset{EdgeStyle/.style={->}}
          % \Edge[label=hf](FOXP2)(GO0044708)
          % \draw[label=binds] (FOXP2) to (MET);
          % \Edge[label=binds](FOXP2)(MET)
          % \Edge[label=activates](MET)(MAPK3)
          % \Edge[label=coexpressed-with](FOXP2)(FOXP4)
          
        \end{tikzpicture}
      }
    \end{column}
    \begin{column}{.4\textwidth}
      \begin{itemize}
      \item FOXP2 + binds - MET = 0
      \item MAP + activates - MAPK3 = 0
      \item MET + binds - FOXP2 = 0
      \item ST7 + hasFunction - {\tt GO:0044708} = 0
      \item ...
      \end{itemize}
    \end{column}
  \end{columns}
\end{frame}

\begin{frame}
  \frametitle{Translating embeddings}
  \centerline{\includegraphics[width=1\textwidth]{transe-algorithm.png}}

  {\tiny Bordes et al. (2013). Translating Embeddings for
    ModelingMulti-relational Data.}
\end{frame}

\begin{frame}
  \frametitle{Some properties of TransE}
  \begin{itemize}
  \item graph-based
    \begin{itemize}
    \item works well on RDF graphs
    \item and ontology graphs
    \end{itemize}
  \item 1:1 relations only
    \begin{itemize}
    \item not suitable for hierarchies (1-N relations)
    \item not suitable for N-N relations
    \item no transitive, symmetric, reflexive relations
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Translating embeddings}
  \centerline{\includegraphics[width=.7\textwidth]{transh-figure.png}}
\end{frame}

\begin{frame}
  \frametitle{Translating embeddings}
  \centerline{\includegraphics[width=.7\textwidth]{transr-figure.png}}
\end{frame}

\begin{frame}
  \frametitle{Translating embeddings}
  \centerline{\includegraphics[width=\textwidth]{loss-functions-kg.png}}
  {\tiny Wang et al. Knowledge Graph Embedding: A Survey ofApproaches and Applications.}
\end{frame}

\begin{frame}
  \frametitle{PyKEEN}
  \begin{itemize}
  \item Python package to generate knowledge graph embeddings
  \item supports many different graph embedding types: TransE, TransR,
    TransD, RESCAL, etc.
  \item hyperparameter optimization (``HPO'') and evaluation included
  \item \url{https://github.com/SmartDataAnalytics/PyKEEN}
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Some limitations}
  \begin{itemize}
  \item graph-based (same as random walks):
    \begin{itemize}
    \item ontologies are not graphs!
    \item converting ontologies to graphs loses information
    \item no axioms, no definitions
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Jupyter excercise}
  \begin{itemize}
  \item run the PyKEEN part of {\tt graph.ipynb}
  \item again: this may take a while
  \item you can also explore
    \url{https://github.com/SmartDataAnalytics/PyKEEN}
  \item try to expand the notebook to predict ``new'' relations
    \begin{itemize}
    \item using numpy directly, or PyKEEN's predictions methods
    \end{itemize}
  \end{itemize}
\end{frame}

\subsection{Syntactic approaches}

\begin{frame}
  \frametitle{Ontologies: axioms, not graphs!}
    \includegraphics[width=1\textwidth]{bcellapoptosis.png}
\end{frame}

\begin{frame}
  \frametitle{Ontologies: axioms, not graphs!}
  Gene Ontology:
  \begin{itemize}
  \item {\tt behavior DisjointWith: 'developmental process'}
  \item {\tt behavior SubclassOf: only-in-taxon some metazoa}
  \item {\tt 'cell proliferation' DisjointWith: in-taxon some fungi}
  \item {\tt 'cell growth' EquivalentTo: growth and ('results in
      growth of' some cell)}
  \item ...
  \end{itemize}
\end{frame}

% \begin{frame}
%   \frametitle{Ontologies: axioms, not graphs!}
%   \begin{itemize}
%   \item converting ontologies to graphs
%     \begin{itemize}
%     \item loses information
%     \end{itemize}
%   \item relations between ontologies
%   \end{itemize}
% \end{frame}

\begin{frame}
  \frametitle{Ontology embeddings}
  \begin{definition}
    Let $O = (\Sigma = (C, R, I); ax; \vdash)$ be an ontology with a set of
    classes $C$, a set of relations $R$, a set of instances $I$, a set
    of axioms $ax$ and an inference relation $\vdash$. An ontology
    embedding is a function $f_\eta : C \cup R \cup I \mapsto
    \Re^n$ (or $\Sigma(O) \mapsto \Re^n$. % (subject to certain constraints).
  \end{definition}
  \pause For example, we can use co-occurrence within $ax^\vdash$ to
  constrain the embedding function, where the constraints on
  co-occurrence are formulated using the Word2Vec skipgram model.
\end{frame}

\begin{frame}
  \frametitle{Onto2Vec}
  \centerline{\includegraphics[width=\textwidth]{onto2vecflow.png}}
\end{frame}

\begin{frame}
  \frametitle{Predicting PPIs: trainable similarity measures}
  \centerline{\includegraphics[width=.45\textwidth]{YSTUnsuper1.png}\includegraphics[width=.45\textwidth]{YstUnsup2.png}}

   {\tiny Smaili et al. Onto2Vec: joint vector-based representation of
     biological entities and their ontology-based annotations.}
\end{frame}

\begin{frame}
  \frametitle{Visualizing embeddings}
  \centerline{\includegraphics[width=.9\textwidth]{updtsne.jpg}}
\end{frame}

\begin{frame}
  \frametitle{Combination with text}
  \begin{itemize}
  \item ontologies contain more than axioms:
    \begin{itemize}
    \item labels, synonyms, definitions, authors, etc.
    \end{itemize}
  \item Description Logic axioms != natural language
  \item transfer learning: learn on one domain/task, apply to another
    \begin{itemize}
    \item e.g.: learn on literature, apply to ontologies
    \item words have ``meaning'' in literature, Description Logic
      symbols have ``meaning'' in ontology axioms
    \end{itemize}
  \item Ontologies Plus Annotations 2 Vec (OPA2Vec) combines both
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Ontologies Plus Annotations 2 Vec}
  \centerline{\includegraphics[width=1\textwidth]{opaworkflow16.png}}
\end{frame}

\begin{frame}
  \frametitle{Axioms contribute to prediction tasks: GO and GO-PLUS}
    % \processtable
    % \caption{AUC values of ROC curves for PPI prediction for
    %   GO-Plus and GO using Onto2Vec (cosine similiarity) and
    %   Onto2Vec-NN (neural network).\label{Tab:GOplus}}
    { \begin{tabularx}{\columnwidth}{XXXXXXX}\toprule & {}& {} &
                                                                 Human & Yeast & Arabidopsis\\\midrule
        $GO\_Onto2Vec$ & {} &{}& 0.7660 & 0.7701 & 0.7559 \\
        $GO\_Onto2Vec\_NN$ & {} & {}& 0.8779& 0.8711 & 0.8364 \\
        $GO\_plus\_Onto2Vec$ & {} & {}& 0.7880& 0.7943 & 0.7889 \\
        $GO\_plus\_Onto2Vec\_NN$ &{} & {}& \textbf{0.9021}&\textbf{0.8937} & \textbf{0.8834}\\
        \hline
      \end{tabularx}}{}
\end{frame}

\begin{frame}
  \frametitle{Evaluating individual axioms}
%  Testing how much each ontologies' axioms contribute to predictions:
%  \begin{resizebox}{\textwidth}{!}{
  Testing how much each ontologies' axioms contribute to predictions:
  \tiny
      \begin{tabularx}{\linewidth}{X|XX|XX}
        \toprule
        {} & \multicolumn{2}{c}{\textbf{Human}} & \multicolumn{2}{c}{\textbf{Arabidopsis}}\\
        \midrule
        {} & \textbf{Onto2Vec}&\textbf{Onto2Vec\_NN} &\textbf{Onto2Vec}&\textbf{Onto2Vec\_NN} \\
        \midrule
        GO (Baseline) &0.7660 &0.8779  & 0.7559 & 0.8364 \\
        ChEBI &0.7899\textcolor{blue}{(+0.0239)}& 0.8914\textcolor{blue}{(+0.0135)}  & 0.7703\textcolor{blue}{(+0.0144)}& 0.8518\textcolor{blue}{(+0.0154)} \\
        PO &0.7752\textcolor{blue}{(+0.0092)} & 0.8776\textcolor{red}{(-0.0003)} & 0.7671\textcolor{blue}{(+0.0112)} & 0.8469\textcolor{blue}{(+0.0105)}\\
        CL & 0.7743\textcolor{blue}{(+0.0083)} & 0.8810\textcolor{blue}{(+0.0031)} & 0.7612\textcolor{blue}{(+0.0053)}& 0.8371\textcolor{blue}{(+0.0007)}\\
        PATO & 0.7657\textcolor{red}{(-0.0003)} & 0.8768\textcolor{red}{(-0.0011)} & 0.7563\textcolor{blue}{(+0.0004)} & 0.8380\textcolor{blue}{(+0.0016)}\\
      \end{tabularx}
%    }
%  \centerline{\includegraphics[width=1\textwidth]{pato-eval1.png}}
\end{frame}

\begin{frame}
  \frametitle{Evaluating definitions}
  Testing how much each ontologies' annotation properties contribute to predictions:
  \tiny
      \begin{tabularx}{\linewidth}{X|XX|XX}
        \toprule
        {} & \multicolumn{2}{c}{\textbf{Human}} & \multicolumn{2}{c}{\textbf{Arabidopsis}}\\
        \midrule
        {} & \textbf{Onto2Vec}&\textbf{Onto2Vec\_NN} &\textbf{Onto2Vec}&\textbf{Onto2Vec\_NN} \\
        \midrule
        GO (Baseline)&0.8727 &0.9033  & 0.8613 & 0.8903 \\
        ChEBI & 0.8571\textcolor{red}{(-0.0156)} &0.8801\textcolor{red}{(-0.0232)} &0.8601\textcolor{red}{(-0.0012)}& 0.8880\textcolor{red}{(-0.0023)}\\
        PO & 0.8680\textcolor{red}{(-0.0047)}&0.8824\textcolor{red}{(-0.0209)} & 0.8632\textcolor{blue}{(+0.0019)} & 0.8908\textcolor{blue}{(+0.0005)}\\
        CL & 0.8811\textcolor{blue}{(+0.0084)}&0.9037\textcolor{blue}{(+0.0004)}  & 0.8614\textcolor{blue}{(+0.0001)} & 0.8899\textcolor{red}{(-0.0004)}\\
        PATO & 0.8562\textcolor{red}{(-0.0165)}& 0.8711\textcolor{red}{(-0.0322)} & 0.8544\textcolor{red}{(-0.0069)}& 0.8860\textcolor{red}{(-0.0043)} \\
      \end{tabularx}
%  \centerline{\includegraphics[width=1\textwidth]{pato-eval2.png}}
\end{frame}

\begin{frame}
  \frametitle{OPA2Vec}
  \begin{itemize}
  \item \url{https://github.com/bio-ontology-research-group/opa2vec}
  \item command line tool
    \begin{itemize}
    \item input: OWL ontology, set of entities with annotations/associations
    \item output: vectors for each class and entity
    \end{itemize}
  \item includes Elk and HermiT
  \item limitations: word-based
    \begin{itemize}
    \item still ignores semantics!
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{OPA2Vec Jupyter excercise}
  \begin{itemize}
  \item open the notebook {\tt OPA2Vec.ipynb}
  \item run the whole notebook
    \begin{itemize}
    \item this should be relatively fast and not take too much time on
      a modern laptop
    \end{itemize}
  \item play with the prediction methods (cosine similarity)
  \end{itemize}
\end{frame}

\subsection{Model-theoretic approaches}

\begin{frame}
  \frametitle{Description Logic EL++}
  \centering
  \resizebox{.8\textwidth}{!}{
    
    \begin{tabular}{|p{1.7cm}|c|p{3.7cm}|}
      \hline
      {\bf} Name & Syntax & Semantics \\
      \hline
      top & $\top$ & $\Delta^{\mathcal{I}}$ \\
    \hline
    bottom & $\bot$ & $\emptyset$ \\
    \hline
    nominal & $\{ a \} $ & $\{ a^{\mathcal{I}} \}$ \\
    \hline
    conjunction & $C \sqcap D$ & $ C^{\mathcal{I}} \cap
                                 D^{\mathcal{I}}$ \\
    \hline
    existential restriction & $\exists r.C$ & $ \{ x \in
                                              \Delta^{\mathcal{I}} |
                                              \exists y \in
                                              \Delta^{\mathcal{I}} :
                                              (x,y) \in
                                              r^{\mathcal{I}} \land y
                                              \in C^{\mathcal{I}} \} $
    \\
    \hline
    generalized concept inclusion & $C \sqsubseteq D$ &
                                                        $C^{\mathcal{I}}
                                                        \subseteq
                                                        D^{\mathcal{I}}$
    \\
    \hline
    role inclusion & $r_1 \circ ... \circ r_n \sqsubseteq r$ &
                                                               $r_1^{\mathcal{I}}
                                                               \circ
                                                               ... \circ
                                                               r_n^{\mathcal{I}}
                                                               \subseteq
                                                               r^{\mathcal{I}}$
    \\
    \hline
    
  \end{tabular}
}
\end{frame}

\begin{frame}
  \frametitle{EL Embeddings}
  \begin{itemize}
  \item given a theory/ontology $T$ with signature $\Sigma(T)$
  \item aim: find $f_e: \Sigma(T) \mapsto \Re^n$ s.t. $f_e(\Sigma(T))$
    is a model of $T$ ($f_e(\Sigma(T)) \models T$)
    \pause
  \item more general: find an algorithm that maps symbols (signatures)
    into $\Re^n$ so that the {\em semantics} of the symbol (expressed
    through axioms and explicit in model structures) is preserved
    \pause
  \item any consistent \el theory has infinite models
    \pause
  \item any consistent EL++ theory has models in $\mathbb{R}^n$
    (Loewenheim-Skolem, upwards)
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Key idea}
  \begin{itemize}
  \item for all $r \in \Sigma(T)$ and $C \in \Sigma(T)$, define
    $f_e(r)$ and $f_e(C)$
  \item $f_e(C)$ maps to points in an open $n$-ball such that
    $f_e(C) = C^{\mathcal{I}}$:
    $C^{\mathcal{I}} = \{ x \in \mathbb{R}^n | \norm{f_e(C) - x} <
    r_e(C) \}$
    \begin{itemize}
    \item these are the {\em extension} of a class in $\Re^n$
    \end{itemize}
  \item $f_e(r)$ maps a binary relation $r$ to a vector such that
    % the set of tuples ($\mathbb{R}^n \times \mathbb{R}^n$) with
    % $f_e(r) = r^{\mathcal{I}}$:
    $r^{\mathcal{I}} = \{ (x,y) | x + f_e(r) = y \}$
    \begin{itemize}
    \item that's the TransE property for {\em individuals}
    \end{itemize}
  \item use the axioms in $T$ as constraints
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Algorithm}
  \begin{itemize}
  \item normalize the theory:
    \begin{itemize}
    \item every \el theory can be expressed using four normal forms
      (Baader et al., 2005)
    \end{itemize}
  \item eliminate the ABox: replace each individual symbol with a
    singleton class: $a$ becomes $\{a\}$
  \item rewrite relation assertions $r(a,b)$ and class
    assertions $C(a)$ as $\{ a \} \sqsubseteq \exists r.\{ b \}$ and
    $\{ a \} \sqsubseteq C$
    \begin{itemize}
    \item something to remember for the next class-vs-instance discussion?
    \end{itemize}
  \item normalization rules to generate:
    \begin{itemize}
    \item $C \sqsubseteq D$
    \item $C \sqcap D \sqsubseteq E$
    \item $C \sqsubseteq \exists R.D$
    \item $\exists R.C \sqsubseteq D$
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Algorithm: loss functions}
  \begin{equation}
    \label{eqn:nf1}
    \begin{split}
      & loss_{C \sqsubseteq D}(c,d) = \\
      & \max(0, \norm{f_\eta(c) - f_\eta(d)} + r_\eta(c) - r_\eta(d) - \gamma) \\
      & + |\norm{f_\eta(c)} - 1| + |\norm{f_\eta(d)} - 1|
    \end{split}
  \end{equation}
\end{frame}

\begin{frame}
  \frametitle{Algorithm: loss functions}
  Let
  $h=\frac{r_\eta(c)^2-r_\eta(d)^2+\norm{f_\eta(c) -
      f_\eta(d)}^2}{2\norm{f_\eta(c) - f_\eta(d)}}$, then the center and
  radius of the smallest $n$-ball containing the intersection of
  $\eta(C)$ and $\eta(D)$ are
  $f_\eta(c)+\frac{h}{\norm{f_\eta(c) -
      f_\eta(d)}}(f_\eta(d)-f_\eta(c))$ and $\sqrt{r_\eta(c)^2-h^2}$.
\end{frame}

\begin{frame}
  \frametitle{Algorithm: loss functions}
  \begin{equation}
    \label{eqn:nf3}
    \begin{split}
      & loss_{C \sqsubseteq \exists R.D}(c,d,r) = \\
      & \max(0, \norm{f_\eta(c) + f_\eta(r) - f_\eta(d)}  + r_\eta(c) - r_\eta(d) - \gamma) \\
      & + |\norm{f_\eta(c)} - 1| + |\norm{f_\eta(d)} - 1|
    \end{split}
  \end{equation}
\end{frame}

\begin{frame}
  \frametitle{Algorithm: loss functions}
  \begin{equation}
    \label{eqn:nf4}
    \begin{split}
      & loss_{\exists R.C \sqsubseteq D}(c,d,r) = \\
      & \max(0, \norm{f_\eta(c) - f_\eta(r) - f_\eta(d)} - r_\eta(c) - r_\eta(d) - \gamma) \\
      & + |\norm{f_\eta(c)} - 1| + |\norm{f_\eta(d)} - 1|
    \end{split}
  \end{equation}
\end{frame}

\begin{frame}
  \frametitle{Algorithm: loss functions}
  \begin{equation}
    \label{eqn:disjoint}
    \begin{split} 
      &loss_{C \sqcap D \sqsubseteq \bot}(c,d,e) = \\
      & \max(0, r_\eta(c) + r_\eta(d) - \norm{f_\eta(c) - f_\eta(d)} + \gamma) \\
      & + |\norm{f_\eta(c)} - 1| + |\norm{f_\eta(d)} - 1|
    \end{split}
  \end{equation}
\end{frame}


\begin{frame}
  \frametitle{EL Embeddings}
  \centerline{\animategraphics[loop,controls,width=.7\textwidth]{12}{embeds-frame-}{0}{99}}
  \begin{itemize}
  \item model with $\Delta = R^n$
  \item support quantifiers, negation, conjunction,...
  \end{itemize}
  {\tiny IJCAI 2019}
\end{frame}

\begin{frame}
  \frametitle{Jupyter excercise}
  
\end{frame}

% \begin{frame}
%   \frametitle{Hands-on part}
%   \begin{itemize}
%   \item run the machine learning with ontologies part
%   \item explore the different similarity measures
%   \item repeat what you have done with semantic similarity using the
%     ontology embeddings
%   \end{itemize}
% \end{frame}

% \section{Applications}

% \begin{frame}
%   \frametitle{How to measure similarity?}
%   \begin{itemize}
%   \item vector-based similarity measure
%   \item cosine similarity: $sim(X,Y) = \frac{\sum_{i=1}^n X_i
%       Y_i}{\sqrt{\sum_{i=1}^n X_i^2} \sqrt{\sum_{i=1}^n Y_i^2}} $
%     \begin{itemize}
%     \item bounded between $[-1,1]$
%     \end{itemize}
%   \item Euclidean distance: $sim(X,Y) = \sqrt{\sum_{i=1}^n (X_i - Y_i)^2}$
%     \begin{itemize}
%     \item not bounded (and rarely used)
%     \end{itemize}
%   \item any other kind of function
%     \begin{itemize}
%     \item Neural Networks can approximate {\em any} function
%       (universal approximation theorem)
%     \item ``trainable'' semantic similarity measures
%     \item will need training data
%     \end{itemize}
%   \end{itemize}
% \end{frame}



% \begin{frame}
%   \frametitle{Applications of semantic similarity}
%   \centerline{\includegraphics[height=\textheight]{vision1.pdf}}
% \end{frame}

% \begin{frame}
%   \frametitle{Applications of semantic similarity}
%   \centerline{\includegraphics[height=\textheight]{similarity.eps}}
% \end{frame}

% \begin{frame}
%   \frametitle{Applications of semantic similarity}
%   \begin{itemize}
%   \item same kind of entity, same ontology:
%     \begin{itemize}
%     \item $x$ is associated with $y$
%     \item $z$ is similar to $x$
%     \item therefore: $z$ may {\em also} be associated with $y$
%     \end{itemize}
%   \item candidate genes (polygenic disease):
%     \begin{itemize}
%     \item FunSimMat: similar function $\Rightarrow$ similar/same
%       disease
%     \item side effect similarity: similar side effects $\Rightarrow$
%       similar targets/indications
%     \end{itemize}
%   \end{itemize}
% \end{frame}

% \begin{frame}
%   \frametitle{Applications of semantic similarity}
%   \begin{itemize}
%   \item different kind of entity, same ontology:
% %  \item candidate genes (monogenic and polygenic disease):
%     \begin{itemize}
%     \item Phenomizer: genotype $x$ associated with phenotypes $a$;
%       patient $y$ has symptoms $b$; $a$ is similar to $b$; therefore:
%       $x$ causes the symptoms in $b$
%     \item PhenomeNET: similar to Phenomizer but using model organism
%       phenotypes (knockouts)
%     \item PhenomeDrug: knockout of gene $x$ causes phenotypes $a$;
%       drug $y$ causes side effects $b$; $a$ is similar to $b$;
%       therefore: drug $y$ inhibits $x$ (or: phenotypes $b$ are caused
%       by inhibition of $x$)
%     \item needs to compare model organism phenotypes and human
%       phenotypes $\Rightarrow$ ontology alignment/integration/mapping
%     \end{itemize}
%   \end{itemize}
% \end{frame}

% \begin{frame}
%   \frametitle{Applications of semantic similarity}
%   semantic similarity and text mining:
%   \begin{itemize}
%   \item find all occurrences of classes of one (or more) ontologies in text
%     \begin{itemize}
%     \item using lexical matching or semantic annotations
%       of text
%     \item TextPresso (\url{http://www.textpresso.org/}), NCBO
%       Annotator (\url{https://bioportal.bioontology.org/annotator}),
%       WhatIzIt (\url{http://www.ebi.ac.uk/webservices/whatizit/info.jsf})
%     \item ontology-specific text normalization tools
%       \begin{itemize}
%       \item DNorm (diseases), GNorm (gene names), OSCAR (chemicals), ...
%       \end{itemize}
%     \end{itemize}
%   \item use for database construction (automatic annotation), relation
%     extraction, network construction (co-occurrence network), etc.
%   \end{itemize}
% \end{frame}

% \begin{frame}
%   \frametitle{Applications of semantic similarity}
%   \centerline{http://aber-owl.net/aber-owl/diseasephenotypes/}
%   \begin{itemize}
%   \item find phenotypes (signs and symptoms) associated with common
%     diseases
%     \begin{itemize}
%     \item no resource available for comparison
%     \end{itemize}
%   \item pattern-based mining of literature with Aber-OWL: PubMed
%   \item evaluation (of genetically based disease phenotypes) with
%     experimentally validated disease genes
%   \end{itemize}
% \end{frame}

% \begin{frame}
%   \frametitle{Applications of semantic similarity}
%   \framesubtitle{http://aber-owl.net/aber-owl/diseasephenotypes/}
%   \centerline{\includegraphics[width=1\textwidth]{aber-owl-plague.png}}
% \end{frame}

% \begin{frame}
%   \frametitle{Applications of semantic similarity}
%   \framesubtitle{http://aber-owl.net/aber-owl/diseasephenotypes/}
%   \centerline{\includegraphics[width=1\textwidth]{pmi-auc-plot.pdf}}
% \end{frame}

% \begin{frame}[plain]
%   \frametitle{Applications of semantic similarity}
%   \centerline{\includegraphics[height=1\textheight]{network.eps}}
% \end{frame}

% \begin{frame}
%   \frametitle{Applications of semantic similarity}
%   \begin{itemize}
%   \item semantic similarity can be used as features in machine
%     learning models
%     \begin{itemize}
%     \item when annotation space is too large
%       \begin{itemize}
%       \item e.g., GO: 50,000 classes
%       \item replace binary representation
%       \end{itemize}
%     \item to incorporate background knowledge
%       \begin{itemize}
%       \item semantic similarity encodes {\em implicitly} for ontology
%         structure and axioms
%       \item encodes for {\em specificity} of classes
%       \end{itemize}
%     \item negative: reduce all annotations to single value
%       \begin{itemize}
%       \item leads to loss of information
%       \item but is easier to use by many machine learning methods
%       \end{itemize}
%     \end{itemize}
%   \end{itemize}
% \end{frame}

% \begin{frame}
%   \frametitle{Applications of semantic similarity}
%   \begin{tikzpicture}[remember picture,overlay]
%     \node[at=(current page.center)] {
%       \centerline{\includegraphics[height=1\textheight]{pvp.pdf}}
%     };
%   \end{tikzpicture}
% \end{frame}

% {
% \setbeamercolor{background canvas}{bg=}
% \includepdf[pages=1-3]{hh-pvp2.pdf}
% }

% \begin{frame}
%   \frametitle{Summary}
%   \begin{itemize}
%   \item many semantic similarity measures
%     \begin{itemize}
%     \item graph-based
%     \item feature-based
%     \end{itemize}
%   \item useful for similarity-based prediction
%     \begin{itemize}
%     \item similar entities $\Rightarrow$ guilt-by-association
%     \item different entities
%     \end{itemize}
%   \item combine with data and text mining
%   \item features in machine learning methods
%   \end{itemize}
% \end{frame}

% \begin{frame}
%   \frametitle{Acknowledgements}
%   \begin{itemize}
%   \item Sarah Alghamdi
%   \item Mona Alsharani
%   \item Imene Boudellioua
%   \item Senay Kafkas
%   \item Maxat Kulmanov
%   \item Fatima Zohra Smaili
%   \end{itemize}
% \end{frame}

% \begin{frame}
%   \frametitle{Hands-on: semantic similarity}
%   \begin{itemize}
%   \item if you have not done so {\em before} the tutorial, don't start
%     now
%     \begin{itemize}
%     \item you need to download {\em a lot} of data
%     \item you can just follow our demonstration and try later
%     \item (unless Internet is exceptionally fast for a conference
%       Wifi, then just go ahead and do everything now)
%     \end{itemize}
%   \item Jupyter Notebook
%     \begin{itemize}
%     \item notebooks consist of code and rich text fragments
%     \item human readable (with nice figures) {\em and} executable
%     \item need to install the SciJava kernel (default: iPython)
%     \item very widely used
%     \end{itemize}
%   \item
%     \url{https://github.com/bio-ontology-research-group/ontology-tutorial}
%   \end{itemize}
% \end{frame}

% \begin{frame}
%   \frametitle{Hands-on: semantic similarity}
%   In the tutorial, we will
%   \begin{itemize}
%   \item download an ontology
%   \item explore the ontology with OWLAPI
%   \item classify the ontology with an OWL reasoner
%     \begin{itemize}
%     \item and query using an OWL reasoner
%     \end{itemize}
%   \item store the inferred version locally
%   \item use the Semantic Measures Library to:
%     \begin{itemize}
%     \item explore the ontology as graph
%     \item compute similarity between classes
%     \item use different similarity measures
%     \item compare patients to mice
%     \end{itemize}
%   \item learn to use Onto2Vec and OPA2Vec
%   \item you can build on this and extend for your own research!
%   \end{itemize}
% \end{frame}

% \begin{frame}
%   \frametitle{Hands-on: semantic similarity}
%   Do the tutorial...
% \end{frame}

% \begin{frame}
%   \frametitle{Hands-on: semantic similarity}
%   \begin{itemize}
%   \item now play with the Notebook:
%     \begin{itemize}
%     \item look at the results list (check MGI)
%     \item try another disease (check OMIM)
%     \item or a drug effect (check SIDER)
%     \end{itemize}
%   \item you can also test another ontology
%     \begin{itemize}
%     \item GO for functional similarity
%     \item ChEBI for chemical (structural) similarity
%     \item or yeast phenotypes
%     \end{itemize}
%   \end{itemize}
% \end{frame}

\end{document}
%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
