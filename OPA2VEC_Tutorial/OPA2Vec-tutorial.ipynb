{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to the OPA2Vec tutorial session.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "OPA2Vec is a tool that can be used to produce feature vectors for biological entities based on an ontology and its annotations. \n",
    "\n",
    "The source code of OPA2Vec is available at: https://github.com/bio-ontology-research-group/opa2vec/.\n",
    "\n",
    "## Dependencies\n",
    "\n",
    "First of all, we need to prepare the environment to run OPA2Vec. OPA2Vec is implemented in 3 different programming languages python, groovy and perl. The versions used for each language are the following: \n",
    "- python 2.7.5\n",
    "- groovy 2.4.10 JVM:1.8.0_121\n",
    "- perl: v5.16.3\n",
    "\n",
    "OPA2Vec also uses the gensim python library which requires scipy and numpy. Assuming you have numpy and scipy installed, you can install gensim by running the following in your terminal: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "pip install --upgrade gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our enviornment is hopefully ready, we can go ahead and run OPA2Vec. The folder where you found this tutorial contains some files that we could use as input samples, in particular:\n",
    "- *phenomenet.owl*, the file containing the ontology we would like to use in owl format.\n",
    "- *go_associations*, a file containing protein to GO function annotations. \n",
    "- *entities.lst*, an optional file containing the list of biological entities we are interested in getting a vector representation for.\n",
    "\n",
    "\n",
    "Let's go ahead and run OPA2Vec from the command line: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "python runOPA2Vec.py phenomenet.owl go_associations -entities entities.lst -annotations all -reasoner elk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If everything goes well, an output file, *AllVectorResults.lst*, will be created in no more than 20 min and should contain the obtained vector representations. A sample output file *AllVectorResults1* is available in this tutorial.\n",
    "\n",
    "As you can see in the command above, in addition to the two mandatory input files , *phenomenet.owl* and *go_associations*, we have also specified three optional parameters: *all* for the *-annotations* parameter to make OPA2Vec use all annotation properties from the metadata of the ontology, *elk* as our reasoner of choice and the *entities.lst* file.\n",
    "\n",
    "OPA2Vec allows you to choose more optional parameters depending on your data and type of application.  \n",
    "In particular, the optional parameters we are allowed to specify in the command line are :\n",
    " \n",
    "    -embedsize [embedding size]\n",
    "    Size of obtained vectors (will depend on training model)\n",
    "\n",
    "    -windsize [window size]\n",
    "    Window size for word2vec model\n",
    "\n",
    "    -mincount [min count]\n",
    "    Minimum count value for word2vec model\n",
    "\n",
    "    -model [model]\n",
    "    Preferred word2vec architecture, sg or cbow\n",
    "\n",
    "    -annotations [metadata annotations] List of full URIs of annotation properties to be included in metadata separated by a comma . Use 'all' for all annotation properties (default) or 'none' for no annotation property\n",
    "\n",
    "\n",
    "    -pretrained [pre-trained model] Pre-trained word2vec model for background knowledge. If no pre-trained model is specified, the program will assume you have downloaded the default pre-trained model from http://bio2vec.net/data/pubmed_model/ \n",
    "\n",
    "Let's now have a look at what the output file looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "head -45 AllVectorResults1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vectors are printed accross multiple lines which makes them a bit hard to process. We can transform the vectors using the following script to a more convenient format: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# process vectors\n",
    "file=open(\"processed_vectors\",'w')\n",
    "\n",
    "input_file=\"AllVectorResults1\"\n",
    "\n",
    "inf =open (input_file)\n",
    "for line in inf:\n",
    "\t line.strip().replace ('[',\"\").replace(']',\"\\n\")\n",
    "\t file.write (line.strip().replace ('[',\"\").replace(']',\"\\n\")),\n",
    "\n",
    "file.close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our vectors look much better now :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "head -20 processed_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try a few things we can do with our vectors.\n",
    "As an example, given a query protein *p*,let's find the *n* closest proteins to it based on pairwise cosine similarity of the obtained vectors. To do so, we first need to install the sklearn package containing the cosine similarity function in python:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    " apt-get -y install python-sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now go ahead and try to find the 10 closest neighbors to protein *A0A024RBG1* as an example. To speed up the calculation, we fix the set of entities we compare to a set of 1000 entity only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. A6NL82\t0.24056068519081897\n",
      "\n",
      "2. A0A0U1RR11\t0.21344038506854024\n",
      "\n",
      "3. A0A2R8YFB7\t0.20980879136776454\n",
      "\n",
      "4. A0A286YFB4\t0.19988283188103195\n",
      "\n",
      "5. A0A0U1RRI6\t0.19704075439528834\n",
      "\n",
      "6. A0A286YET3\t0.19369666960546184\n",
      "\n",
      "7. A0A286YFG1\t0.1928914756300507\n",
      "\n",
      "8. A6NJ78\t0.19175714812144584\n",
      "\n",
      "9. A0A286YF60\t0.1890638514071129\n",
      "\n",
      "10. A6NNA2\t0.18722186307718114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from scipy.spatial.distance import cosine \n",
    "from itertools import islice\n",
    "\n",
    "#1.Defining query and # of neighbors (coud be given as input)\n",
    "#query =str(sys.argv[1])\n",
    "#n = int (sys.argv[2])\n",
    "query =\"A0A024RBG1\"\n",
    "n=10\n",
    "\n",
    "#2.Reading input: vectors and entities\n",
    "vectors=numpy.loadtxt(\"sample_vectors\");\n",
    "text_file=\"sample_entities\"\n",
    "classfile=open (text_file)\n",
    "mylist=[]\n",
    "for linec in classfile:\n",
    "\tmystr=linec.strip()\n",
    "\tmylist.append(mystr)\n",
    "\n",
    "\n",
    "#3.Mapping Entities to Vectors\n",
    "vectors_map={}\n",
    "for i in range(0,len(mylist)):\n",
    "\tvectors_map[mylist[i]]=vectors[i,:]\n",
    "\t\n",
    "\n",
    "#4.Calculating cosine similarity to query\n",
    "cosine_sim={}\n",
    "for x in range(0,len(mylist)):\n",
    "\tif (mylist[x]!=query): \t\n",
    "\t\tv1=vectors_map[mylist[x]]\n",
    "\t\tv2=vectors_map[query]\n",
    "\t\tvalue=cosine(v1,v2)\n",
    "\t\tcosine_sim[mylist[x]]=value\n",
    "\n",
    "#5.Retrieving the n closest neighbors to query\n",
    "sortedmap=sorted(cosine_sim,key=cosine_sim.get, reverse=True)\n",
    "iterator=islice(sortedmap,n)\n",
    "i =1\n",
    "for d in iterator:\n",
    "\tprint (str(i)+\". \"+ str(d) +\"\\t\"+str(cosine_sim[d])+\"\\n\")\n",
    "\ti +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
